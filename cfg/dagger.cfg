[DEFAULT]

name = dagger

# Task parameters
env = CoverageARL-v0
pretrain = True
pretrain_epochs = 2000

reducer = sum
n_layers = 2
;aggregation = [1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2]
aggregation = [1,1,1,1,1]
normalize_reward = False


pretrain_dataset =
pretrain_lr = 1e-4
pretrain_ent_coef = 0.000001

pretrain_batch = 20
pretrain_checkpoint_epochs = 5

####################
load_trained_policy =
use_checkpoint = False

# Training parameters
n_env = 4
n_steps = 10

# No RL training
total_timesteps = 0


[_6]


;aggregation = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]
;aggregation = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]