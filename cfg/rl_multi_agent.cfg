[DEFAULT]

name = rl_multi_agent

# Task parameters
env = CoverageARL-v0

# Training parameters
n_env = 4
n_steps = 10
load_trained_policy =
use_checkpoint = False
total_timesteps = 50000000
checkpoint_timesteps = 10000

# Model parameters
policy = MultiAgentGNNFwd
n_gnn_layers = 3
n_layers = 2
latent_size = 32
aggregation = [1,1,1,1,1]
train_lr = 5e-6
;train_lr = 1e-5
cliprange = 10.0
adam_epsilon = 1e-6
vf_coef = 0.01
ent_coef = 0.000001
reducer = mean


[_420]